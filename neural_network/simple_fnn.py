#! /usr/bin/python3
import numpy as np

def sigmoid(x) :
	return 1/(1+np.exp(-x))

def softmax(a) : 
	c = np.max(a)
	exp_a = np.exp(a-c)
	sum_exp_a = np.sum(exp_a)
	y = exp_a/sum_exp_a
	return y

def init_network():
	network={}
	network['w1'] = np.array([[0.1,0.3,0.5],[0.2,0.4,0.6]])
	network['b1'] = np.array([0.1,0.2,0.3])
	network['w2'] = np.array([[0.1,0.4],[0.2,0.5],[0.3,0.6]])
	network['b2'] = np.array([0.1,0.2])
	network['w3'] = np.array([[0.1,0.3],[0.2,0.4]])
	network['b3'] = np.array([0.1,0.2])
	return network


def forward(network,x):
	w1,w2,w3 = network['w1'],network['w2'],network['w3']
	b1,b2,b3 = network['b1'],network['b2'],network['b3']
	
	a1 = np.dot(x,w1)+b1
	z1 = sigmoid(a1)
	a2 = np.dot(z1,w2)+b2
	z2 = sigmoid(a2)
	a3 = np.dot(z2,w3)+b3
	z3 = sigmoid(a3)
	
	return z3

network = init_network()
x = np.array([1.0,0.5])
y = forward(network,x)
result=softmax(y)
print(result)
	
